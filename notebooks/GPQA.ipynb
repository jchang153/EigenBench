{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389837f6",
   "metadata": {},
   "source": [
    "## Getting comparisons on GPQA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fe5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "events = [name for name in os.listdir('transcript_gpqa/') if '2025' in name]\n",
    "data = []\n",
    "for name in events:\n",
    "    with open(f\"transcript_gpqa/{name}/evaluations.json\", 'r') as file:\n",
    "        data.extend(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Grok 3 Mini\": \"grok-3-mini\",\n",
    "    # \"Gemini 2.5 Flash\": \"gemini-2.5-flash\",\n",
    "    # \"GPT oss 120b\": \"gpt-oss-120b\",\n",
    "    \"Qwen3 235B A22B Instruct 2507\": \"qwen/qwen3-235b-a22b-2507\",\n",
    "    \"Kimi K2 0905\": \"moonshotai/kimi-k2-0905\",\n",
    "    \"Qwen3 Next 80B A3B Instruct\": \"qwen/qwen3-next-80b-a3b-instruct\",\n",
    "    \"Llama 4 Maverick\": \"meta-llama/llama-4-maverick\",\n",
    "    \"DeepSeek V3 0324\": \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"Gemini 2.5 Flash Lite\": \"gemini-2.5-flash-lite\",\n",
    "    \"Gemini 2.0 Flash\": \"gemini-2.0-flash-001\",\n",
    "    \"Llama 4 Scout\": \"meta-llama/llama-4-scout\",\n",
    "    \"Gemini 2.0 Flash Lite\": \"gemini-2.0-flash-lite-001\",\n",
    "    \"Llama 3.3 70b Instruct\": \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"Qwen2.5 72B Instruct\": \"qwen/qwen-2.5-72b-instruct\",\n",
    "    # \"Qwen3 235B A22B\": \"qwen/qwen3-235b-a22b\",\n",
    "    \"Llama 3.1 70B Instruct\": \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"GPT 4o mini\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"GPT 3.5 Turbo\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "model_nicks = list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "714c0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data2 = []\n",
    "for scenario_index in range(448):\n",
    "    subset = [i for i in data if i['scenario_index'] == scenario_index][0]\n",
    "\n",
    "    to_append = {\n",
    "        'subdomain': subset['subdomain'],\n",
    "        'question': subset['question'],\n",
    "        'scenario_index': scenario_index,\n",
    "    }\n",
    "\n",
    "    for model in model_nicks:\n",
    "        if subset[model][1] is not None:\n",
    "            to_append[model] = subset[model]\n",
    "        else:\n",
    "            response = subset[model][0]\n",
    "            try:\n",
    "                match = re.search(r'<answer>(.)</answer>', response).group(1)\n",
    "                if match in ['A', 'B', 'C', 'D']:\n",
    "                    to_append[model] = [response, match]\n",
    "                else:\n",
    "                    raise Exception\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    match2 = re.search(r'boxed{(.)}', response).group(1)\n",
    "                    if match in ['A', 'B', 'C', 'D']:\n",
    "                        to_append[model] = [response, match2]\n",
    "                    else:\n",
    "                        raise Exception\n",
    "                except:\n",
    "                    to_append[model] = [response, None]\n",
    "    data2.append(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf2f7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data2, open('evaluations_gpqa_parsed.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "160b9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'C', 'C', 'A', 'A', 'A', 'A', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'B', 'A', None, 'A', 'B', None, 'A', 'C', 'A', 'C', 'C', 'C', 'A', 'A']\n",
      "13\n",
      "['B', None, 'A', None, 'A', 'B', None, 'B', 'B', 'B', 'A', 'B', 'C', 'C', 'B']\n",
      "12\n",
      "['C', None, 'B', None, None, 'A', None, None, None, 'B', 'B', 'C', 'A', 'B', 'D']\n",
      "9\n",
      "['A', None, 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', None, 'A', 'C']\n",
      "12\n",
      "['A', 'A', 'C', None, 'D', 'B', 'A', 'A', 'C', 'B', 'D', 'A', 'B', 'D', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'B', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'B', 'C', 'C', 'C', 'C', 'B']\n",
      "15\n",
      "['C', 'A', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'B', 'C', 'C', 'B']\n",
      "15\n",
      "['A', 'B', 'A', 'B', 'A', 'D', None, 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "14\n",
      "['B', 'B', 'B', 'B', 'B', 'B', None, 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'D']\n",
      "14\n",
      "['B', 'A', 'A', 'A', 'A', 'A', None, 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'B']\n",
      "14\n",
      "['A', None, 'A', None, 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "12\n",
      "['A', None, 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', None, 'A', 'D', 'C']\n",
      "12\n",
      "['B', 'B', 'D', 'B', 'A', 'A', None, 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'C']\n",
      "14\n",
      "['A', 'A', 'B', 'B', 'A', 'D', 'A', 'D', 'B', 'D', 'A', 'D', 'D', 'D', 'A']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'A', None, 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A']\n",
      "12\n",
      "['A', None, 'A', 'C', 'C', 'A', None, None, 'C', 'A', 'B', 'C', 'C', 'B', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'C']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'A', None, 'A', 'C', 'D', 'C', 'D', 'A', 'A', 'B']\n",
      "12\n",
      "['D', 'D', 'D', 'C', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "15\n",
      "['B', 'A', 'C', 'A', 'B', 'D', None, 'D', 'B', 'D', 'A', 'D', 'A', 'D', None]\n",
      "13\n",
      "['D', 'D', 'B', 'B', 'A', 'A', None, 'D', 'C', 'B', 'A', 'B', 'A', 'D', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'D', 'A', 'A', 'D', 'D', 'A', 'A', 'A', 'B', 'D', 'A']\n",
      "15\n",
      "['c', 'A', 'A', 'A', 'C', 'A', None, 'C', 'B', 'A', 'D', 'C', 'C', 'D', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C', 'A', 'D', 'A', 'A', 'D', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'D', 'A']\n",
      "15\n",
      "['A', 'B', 'A', None, 'B', 'A', None, None, None, 'A', 'A', 'A', 'B', 'A', 'A']\n",
      "11\n",
      "['A', 'A', 'C', 'A', 'C', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A']\n",
      "15\n",
      "['C', 'A', 'C', 'A', 'A', 'A', None, 'C', 'C', 'A', 'C', 'B', 'C', 'C', 'A']\n",
      "14\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A']\n",
      "15\n",
      "['D', 'A', 'D', 'A', 'A', 'A', 'A', 'D', 'C', 'D', 'A', None, 'A', 'C', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'C', 'D', 'D', 'D', 'C', 'D', None]\n",
      "14\n",
      "['A', 'B', 'B', 'D', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', None]\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'B', 'A']\n",
      "14\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', None, 'B', 'C', 'B', 'A', 'A', 'B']\n",
      "14\n",
      "['B', 'B', 'C', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'C', 'C', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'C', 'A', 'D', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'D', 'A']\n",
      "15\n",
      "['A', 'D', 'B', None, 'A', 'A', 'A', 'D', 'C', 'D', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'C', 'D', 'D', 'D', None, 'D', None, 'B', 'A', 'B', 'A', 'C', 'A']\n",
      "13\n",
      "['A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'C', 'B', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'B', 'C', 'A', 'A', 'A', 'B', 'B', 'C', 'B', 'B', 'A', 'A', 'D', 'C']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'B', None, 'A', None, 'B', 'A', 'B', 'A', 'D', 'D']\n",
      "11\n",
      "['A', None, 'A', None, 'A', 'C', None, 'D', None, 'D', 'B', 'B', 'D', 'A', 'A']\n",
      "11\n",
      "['D', 'B', 'B', 'B', 'D', 'D', 'D', 'D', 'B', 'D', 'B', 'A', 'B', 'B', 'C']\n",
      "15\n",
      "['C', None, 'A', None, 'D', 'D', 'D', 'A', 'C', 'C', 'A', 'B', 'C', 'D', 'D']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'C', 'B', 'D', 'A', 'B']\n",
      "14\n",
      "['A', None, 'A', 'A', 'A', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'D']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'D', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D']\n",
      "15\n",
      "['C', 'A', 'A', 'D', 'C', 'C', None, 'C', 'D', 'C', 'C', 'D', 'D', 'D', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'C', 'C', 'A', 'C', 'C', 'B', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'C', 'A', 'A', 'A', 'C', 'B']\n",
      "15\n",
      "['A', 'A', 'B', 'A', 'B', 'A', 'C', 'B', 'B', 'A', 'C', 'C', 'C', 'B', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'C', 'A', 'A', 'B', None, 'A', 'C', 'C', 'C', 'A', 'B']\n",
      "14\n",
      "['C', 'C', 'A', 'C', 'A', 'A', 'A', 'B', 'A', 'C', 'B', 'D', 'C', 'A', 'A']\n",
      "15\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'C', 'B', 'B', 'B', 'C', 'B', 'A', 'D', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'D', None, 'B', 'D', 'A', 'A', 'B', 'B', 'A', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C']\n",
      "15\n",
      "['D', None, 'B', None, 'A', 'A', None, 'A', 'D', 'C', 'A', 'A', 'A', 'B', 'D']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', None, 'A', 'A', 'B', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'B', None, 'B', None, 'B', 'A', 'B', 'B', 'B', 'B']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B']\n",
      "15\n",
      "['D', 'D', 'D', 'D', 'D', 'D', None, 'D', 'B', 'A', 'A', None, 'A', 'A', 'D']\n",
      "13\n",
      "['A', None, 'C', None, 'C', 'A', None, 'A', 'C', 'C', None, 'C', 'A', 'A', 'A']\n",
      "11\n",
      "['D', None, 'D', 'A', 'C', 'B', 'D', 'D', 'A', 'A', 'A', 'B', 'A', 'A', 'B']\n",
      "14\n",
      "['A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'C', 'B', 'C']\n",
      "14\n",
      "['C', None, 'C', 'A', 'A', 'A', 'A', None, 'C', 'A', 'A', 'A', 'A', 'C', 'C']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'C', 'A', 'A', 'D', 'C', 'D', 'A', 'B', 'C', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', None, 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'B', 'A', 'C', None]\n",
      "13\n",
      "['B', 'B', 'D', 'B', 'D', 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B', 'D', 'D']\n",
      "15\n",
      "['A', 'D', 'D', 'D', 'A', 'D', 'A', None, 'C', 'C', 'D', 'B', 'C', 'B', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'D', 'A', 'D', 'D', 'A', 'D', 'D']\n",
      "15\n",
      "['A', None, 'D', 'A', 'A', 'A', 'D', 'C', 'C', 'D', 'D', 'C', 'C', 'C', 'D']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C', 'C', 'A', 'D', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', None, 'B', None, None, 'B', 'D', 'C', 'D', 'C', 'D', 'C', 'C']\n",
      "12\n",
      "['D', 'D', 'D', 'D', 'D', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'A']\n",
      "15\n",
      "['A', None, 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'A', 'C', 'D', 'D', 'D', 'D', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'C', 'A', 'B', 'A', 'A', None, 'A', 'D']\n",
      "13\n",
      "['A', 'B', 'A', 'D', 'C', 'D', 'D', 'B', 'B', 'A', 'A', 'A', 'D', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'D', 'D', 'D', 'A']\n",
      "15\n",
      "['A', None, 'A', 'A', 'A', 'A', None, 'A', 'A', 'D', 'B', 'A', 'A', 'A', 'D']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', None, 'B', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'B', 'C', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', None, 'B', 'A', None, None, None, 'D', 'A', 'A', 'A', 'A', 'B']\n",
      "11\n",
      "['C', None, 'A', None, 'A', 'C', '3', None, 'C', 'C', None, 'A', 'D', 'A', 'A']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', None]\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'D']\n",
      "14\n",
      "['A', 'D', 'C', None, 'B', 'B', None, 'A', 'B', 'B', 'A', 'B', 'A', 'B', 'B']\n",
      "13\n",
      "['C', 'A', 'A', 'C', 'A', 'C', 'A', 'C', None, 'C', 'C', 'C', 'A', 'C', 'B']\n",
      "14\n",
      "['A', None, 'A', None, 'A', 'A', None, 'A', 'C', None, 'C', 'A', None, 'B', 'C']\n",
      "10\n",
      "['C', None, 'B', None, 'C', 'C', None, 'C', 'C', 'A', 'C', 'A', 'B', 'C', 'C']\n",
      "12\n",
      "['A', None, 'C', None, 'C', 'C', None, 'D', 'C', 'C', 'A', 'C', 'A', 'B', 'D']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D']\n",
      "15\n",
      "['A', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'D', 'A', 'A', 'B', 'D', 'B']\n",
      "15\n",
      "['A', None, 'A', None, None, 'B', None, 'A', 'B', 'B', None, 'B', 'B', 'D', 'D']\n",
      "10\n",
      "['A', 'A', 'A', 'D', 'A', 'A', None, 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'D']\n",
      "14\n",
      "['B', 'D', 'D', 'B', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'B']\n",
      "15\n",
      "['A', None, 'B', None, 'A', 'A', None, None, 'B', 'B', 'D', 'A', 'B', 'B', 'B']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'C', 'A', 'C', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', None, 'B', 'A', 'C', 'D', 'B']\n",
      "13\n",
      "['A', 'A', 'A', None, 'A', 'A', 'A', 'D', None, None, 'A', 'C', 'A', None, 'C']\n",
      "11\n",
      "['A', None, 'A', None, 'D', 'D', None, 'D', 'C', 'A', 'A', 'D', 'D', 'C', 'C']\n",
      "12\n",
      "['A', 'C', 'D', None, 'B', 'B', None, 'B', None, 'B', 'A', 'D', 'A', 'B', 'C']\n",
      "12\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'D', 'A', 'D', 'A', 'A', 'A', 'A', 'D']\n",
      "15\n",
      "['D', 'B', 'B', 'D', 'A', 'B', 'D', 'B', 'D', 'A', 'D', 'A', 'D', 'D', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', None, 'B', 'A', 'A', 'A', 'A', None]\n",
      "12\n",
      "['C', 'B', 'D', 'B', 'C', 'C', None, 'C', 'C', 'C', 'A', 'D', 'C', 'D', 'B']\n",
      "14\n",
      "['A', None, 'C', None, None, 'A', None, 'A', 'A', 'B', 'C', 'C', 'C', 'A', 'A']\n",
      "11\n",
      "['A', 'A', 'C', None, 'A', None, None, 'C', 'D', 'A', 'B', 'A', 'D', 'D', 'D']\n",
      "12\n",
      "['D', 'A', 'A', 'A', 'C', 'C', None, 'A', 'B', 'C', 'A', 'B', 'C', 'B', 'C']\n",
      "14\n",
      "['A', None, 'D', None, None, 'A', None, None, None, 'B', None, None, 'A', 'D', 'A']\n",
      "7\n",
      "['A', None, None, None, None, None, None, 'D', None, 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "8\n",
      "['A', None, None, None, 'A', 'C', None, 'D', 'C', 'D', 'A', 'A', 'C', 'A', 'A']\n",
      "11\n",
      "['A', 'A', None, 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', None, 'A', None, 'A', 'A', None, None, 'B', 'B', 'A', 'B', 'A', 'B', 'A']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B']\n",
      "15\n",
      "['C', 'C', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'B', 'A']\n",
      "14\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "15\n",
      "['A', None, 'A', None, 'B', 'C', None, 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'A']\n",
      "12\n",
      "['B', 'B', 'A', 'A', 'A', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', 'C', 'C', 'B', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['A', None, 'C', 'C', 'B', 'C', None, 'D', 'C', 'B', 'A', 'C', 'B', 'B', 'B']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'D', 'A', None, 'D', 'B', 'D', 'A', 'A', 'C', None, 'C', 'A', 'A', 'A']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'D', 'A', 'C', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'D', 'A', 'B', 'C', 'D']\n",
      "14\n",
      "['A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'D', 'D']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'D', 'C', 'C', 'B', 'D', 'B', 'D', 'D', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'D', None, 'A', 'A', 'A', 'D', None, 'A', 'D', 'D', 'C', 'A', 'D']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'B']\n",
      "15\n",
      "['B', 'C', 'B', 'D', 'B', 'B', 'D', 'C', 'C', 'B', 'B', 'D', 'B', 'C', 'B']\n",
      "15\n",
      "['C', 'A', 'B', 'A', 'C', 'A', None, 'C', 'C', 'B', None, 'C', 'B', 'C', 'A']\n",
      "13\n",
      "['C', None, 'C', None, 'A', 'A', None, 'C', 'C', 'D', 'D', 'C', 'A', 'B', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'C', 'A', 'B', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'D', 'A', 'A', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'C', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None]\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'D', None, 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "14\n",
      "['C', 'C', 'A', 'C', 'C', 'C', None, 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "14\n",
      "['A', 'A', 'A', None, 'A', 'A', None, None, 'A', 'A', 'A', 'A', 'A', 'A', 'D']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'C']\n",
      "14\n",
      "['A', 'C', 'A', 'A', 'D', 'C', 'D', None, 'A', 'D', 'D', 'D', 'A', 'D', 'A']\n",
      "14\n",
      "['C', None, 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'C', 'C', 'A']\n",
      "14\n",
      "['C', 'C', 'A', 'C', 'C', 'C', 'A', 'C', 'C', 'A', 'A', 'C', 'A', 'C', 'D']\n",
      "15\n",
      "['A', None, 'B', None, 'D', 'B', None, 'D', 'A', 'D', 'D', 'A', 'D', 'D', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'B', None]\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'B', 'D', 'D']\n",
      "15\n",
      "['A', 'A', None, 'D', 'D', 'A', 'A', 'A', 'D', 'A', 'A', 'D', 'D', 'A', 'C']\n",
      "14\n",
      "['A', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', None, 'A', None, 'B', 'A', 'C', 'A', 'C', 'C', 'B', 'A', 'B', 'B', 'C']\n",
      "13\n",
      "['C', None, 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'A', 'D']\n",
      "14\n",
      "['A', 'D', 'B', 'A', 'A', 'D', 'B', None, 'B', 'C', 'D', 'A', 'D', 'B', 'B']\n",
      "14\n",
      "['A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, None, 'A', 'C', None, 'A', 'C', 'D', 'A']\n",
      "12\n",
      "['D', None, 'C', None, 'D', 'A', None, 'D', 'D', 'D', None, 'D', 'D', 'D', 'A']\n",
      "11\n",
      "['A', None, 'C', None, 'A', 'A', 'D', 'A', None, 'C', 'B', 'D', 'D', 'C', 'B']\n",
      "12\n",
      "['D', None, 'D', None, 'D', 'D', None, 'D', 'D', 'C', 'D', 'D', 'A', 'D', 'D']\n",
      "12\n",
      "['A', 'C', 'A', 'B', 'C', 'B', 'C', 'B', 'D', 'B', 'C', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['C', None, 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'C', 'C', None, 'C', None, 'A', 'C', 'A', 'C', 'A', 'A']\n",
      "13\n",
      "['A', 'D', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'B', 'A', 'D', 'D', 'D', 'C']\n",
      "15\n",
      "['B', 'A', 'C', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C', 'A', 'C', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', None, 'A', 'A', 'A', None, 'A', 'C', 'A', 'A', 'A', 'A', 'A']\n",
      "13\n",
      "['B', 'B', 'B', None, 'A', 'B', 'B', 'D', 'B', 'B', 'B', 'D', 'B', 'B', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'B', 'C', 'B', 'A', 'C', 'C', 'B', None]\n",
      "14\n",
      "['A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'C', 'B', 'C', 'C']\n",
      "15\n",
      "['A', None, 'A', None, 'B', 'B', None, 'B', 'B', None, 'B', 'D', 'D', 'A', 'D']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', None, 'B', 'A', 'B', 'B', 'B', 'B']\n",
      "14\n",
      "['A', None, 'A', 'A', 'A', 'B', 'A', 'C', 'B', 'A', 'A', 'A', 'A', 'A', 'D']\n",
      "14\n",
      "['A', 'A', 'A', None, 'A', 'D', None, None, 'A', 'C', 'A', 'D', 'A', 'C', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'C', 'B', 'C', 'C', 'C', 'B', 'C', 'C', 'B', 'C', 'D', 'C', 'D', 'D']\n",
      "15\n",
      "['A', None, None, None, 'C', 'A', None, 'A', 'A', 'C', 'A', 'D', 'D', 'D', 'C']\n",
      "11\n",
      "['C', None, 'A', None, 'D', 'C', None, 'A', 'D', 'B', 'B', 'C', None, 'C', 'C']\n",
      "11\n",
      "['C', 'A', None, None, 'C', 'A', 'A', 'C', None, 'A', 'A', 'C', 'A', 'A', 'C']\n",
      "12\n",
      "['D', None, None, None, 'C', 'D', None, None, 'D', 'C', 'B', 'C', 'B', 'D', 'D']\n",
      "10\n",
      "['C', 'C', 'C', 'B', 'C', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'D', 'A', 'B', 'D', None, 'D', 'D', 'A', None, 'D', 'D', 'D', 'B']\n",
      "12\n",
      "['A', None, 'D', None, 'B', 'D', None, 'A', 'D', 'D', 'A', 'D', 'D', 'D', 'B']\n",
      "12\n",
      "['A', None, 'A', 'A', 'B', 'B', 'D', 'B', 'B', 'B', 'A', 'A', 'A', 'C', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'D', 'C', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'D', 'A', 'C', 'D', None, 'B', 'D', 'D', 'A', 'C', 'D', 'D', 'D']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None]\n",
      "14\n",
      "['A', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'D']\n",
      "15\n",
      "['A', None, 'A', None, 'A', None, None, 'A', 'A', 'D', 'D', 'B', 'D', 'B', 'B']\n",
      "11\n",
      "['C', 'C', 'D', None, 'C', 'D', 'C', 'D', 'C', 'C', 'C', 'C', 'D', 'C', 'C']\n",
      "14\n",
      "['A', None, None, None, 'D', 'A', None, 'D', 'D', 'D', 'D', 'D', 'A', 'C', 'D']\n",
      "11\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', None, 'B', 'B', 'A', None]\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'C', 'A', 'D', 'A']\n",
      "15\n",
      "['B', None, 'B', None, None, 'B', None, 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'B', None, 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B']\n",
      "15\n",
      "['B', None, None, None, 'B', 'B', None, 'D', None, 'B', 'A', 'A', 'D', 'D', 'D']\n",
      "10\n",
      "['A', None, 'B', None, None, 'B', None, 'A', None, 'B', 'B', 'B', 'B', 'B', 'C']\n",
      "10\n",
      "['D', None, 'A', 'D', 'D', 'D', None, 'D', None, 'D', 'D', 'D', 'D', 'B', 'C']\n",
      "12\n",
      "['A', 'A', 'A', None, 'A', 'D', None, 'A', 'A', 'A', 'A', 'D', 'A', 'D', 'A']\n",
      "13\n",
      "['A', None, 'B', None, 'B', 'A', None, 'D', None, 'C', 'D', 'A', 'B', 'B', 'A']\n",
      "11\n",
      "['A', None, 'A', None, 'D', 'A', None, 'A', 'D', 'D', 'B', 'C', 'D', 'B', 'C']\n",
      "12\n",
      "['A', None, None, None, 'A', 'A', None, 'C', 'B', 'C', 'A', 'C', 'D', 'D', 'B']\n",
      "11\n",
      "['A', None, 'A', None, 'A', 'B', None, 'A', None, None, None, 'B', 'D', 'D', 'C']\n",
      "9\n",
      "['C', None, 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'B', None]\n",
      "13\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'D', 'D', 'D', 'B', 'D', 'B', 'D', 'D', 'A', 'D', 'C', 'A', 'D', 'D']\n",
      "15\n",
      "['C', None, None, None, 'C', 'C', None, 'D', 'B', 'B', 'B', 'D', 'B', 'B', 'D']\n",
      "11\n",
      "['A', None, 'C', None, 'A', 'B', None, 'C', 'C', 'B', 'C', 'C', 'C', 'C', 'B']\n",
      "12\n",
      "['A', 'A', 'A', None, 'A', 'A', None, 'C', None, 'A', 'D', 'C', 'C', 'A', 'C']\n",
      "12\n",
      "['A', None, 'A', None, None, None, None, 'A', None, 'B', 'B', 'D', 'D', 'B', 'A']\n",
      "9\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', 'C', 'C', None, 'C', 'C', None, 'C', None, 'A', 'C', 'C', 'C', 'C', 'C']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'D', None, 'B', 'B', None, 'B', 'D', 'B', 'D', 'A', 'A', 'C', 'D']\n",
      "12\n",
      "['C', 'A', 'A', 'C', 'C', 'C', 'A', 'C', 'A', 'A', 'C', 'D', 'A', 'D', 'C']\n",
      "15\n",
      "['A', 'B', 'D', 'A', 'C', 'C', 'A', 'B', None, 'C', 'A', 'C', 'B', 'B', 'B']\n",
      "14\n",
      "['D', 'C', 'A', 'D', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'C', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'C', 'A', 'A', 'A', None, 'A', 'A', None, 'C', 'D', 'C', 'B', 'D']\n",
      "13\n",
      "['A', 'A', 'C', 'A', 'A', 'B', 'D', 'D', 'B', 'D', 'A', 'D', 'A', 'A', 'D']\n",
      "15\n",
      "['A', None, 'C', None, 'D', 'A', None, None, 'D', 'A', 'A', 'D', 'A', 'D', 'D']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'D', 'B', 'D', 'B', 'D', 'B']\n",
      "15\n",
      "['C', None, 'B', None, 'B', 'A', None, 'A', 'B', 'A', 'A', 'B', 'C', 'D', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', 'C', 'C', 'D', 'C', 'C', 'D', 'D', 'C', 'C', 'D', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', None, 'A', 'A', 'A', None, 'D', 'D', None, 'D', 'A', 'A', 'A', 'A', 'A']\n",
      "12\n",
      "['D', None, 'D', None, 'A', 'D', None, 'D', 'D', 'C', 'A', 'C', 'C', 'D', 'D']\n",
      "12\n",
      "['D', None, 'C', None, 'D', 'D', 'D', 'D', 'A', 'D', 'D', 'C', 'D', 'A', 'C']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D']\n",
      "15\n",
      "['A', 'B', 'B', 'B', 'A', 'D', 'A', 'C', None, 'C', 'A', 'C', 'B', 'B', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A']\n",
      "15\n",
      "['A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', None, 'B', 'A', 'B', 'C', 'A', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'B', 'A', 'A', None, 'A', 'A']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'C', 'D', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'B', None, 'A', None, 'A', 'B', 'B', 'A', 'A', 'A']\n",
      "13\n",
      "['A', 'D', 'A', 'D', 'D', 'D', 'D', 'D', None, 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'C', 'A', 'A', 'D', 'D', 'C']\n",
      "14\n",
      "['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'A']\n",
      "15\n",
      "['A', None, 'B', None, 'A', 'A', None, None, None, 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "10\n",
      "['D', 'A', 'A', 'A', 'A', 'A', 'D', 'A', None, 'A', 'A', 'A', 'A', 'A', 'B']\n",
      "14\n",
      "['C', None, 'A', None, 'A', 'B', None, 'C', 'A', 'D', 'A', 'D', 'A', 'C', 'B']\n",
      "12\n",
      "['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'A', 'A', 'B', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'A', 'B', 'A', 'B', 'C', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'B', None, None, 'B', 'B', None, 'B', 'A', 'D']\n",
      "12\n",
      "['A', 'A', 'B', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'A', None, 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'D']\n",
      "12\n",
      "['A', 'A', 'B', 'A', 'A', 'B', None, 'A', 'A', 'A', 'B', 'A', 'C', 'C', 'B']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'C']\n",
      "14\n",
      "['A', None, 'B', 'A', 'D', 'C', None, 'B', 'C', 'C', 'C', 'B', 'C', 'C', 'D']\n",
      "13\n",
      "['A', 'C', 'A', None, 'A', 'A', None, 'A', 'A', 'B', 'A', 'B', 'A', 'B', None]\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'B', 'C', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'D', 'D', 'D', 'D', 'D']\n",
      "15\n",
      "['D', 'A', 'A', 'D', 'A', 'D', 'A', 'A', 'D', 'A', 'A', 'D', 'D', 'A', 'D']\n",
      "15\n",
      "['B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['D', None, 'B', None, 'A', 'B', 'D', None, 'B', 'D', 'D', 'B', 'A', 'C', 'A']\n",
      "12\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', None, 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A']\n",
      "14\n",
      "['B', 'A', 'A', None, 'B', 'B', None, 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A']\n",
      "13\n",
      "['C', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'A', 'C', 'A', 'C', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'B', 'B', 'A', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'C', 'A', 'A', 'B', 'A', 'C']\n",
      "15\n",
      "['A', 'A', 'B', 'A', 'C', 'A', None, 'A', None, 'A', 'C', 'C', 'D', 'A', 'A']\n",
      "13\n",
      "['A', None, 'A', None, 'A', 'D', None, None, None, 'D', 'B', 'B', 'B', 'D', 'B']\n",
      "10\n",
      "['C', 'C', 'A', 'A', 'A', 'C', 'C', 'A', 'A', 'C', 'D', 'C', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, None, 'A', 'D', 'B', 'A', 'D', 'C', 'C']\n",
      "13\n",
      "['A', None, 'A', 'A', 'D', 'D', 'B', 'A', 'A', 'A', 'A', 'B', 'D', 'D', 'B']\n",
      "14\n",
      "['A', 'A', 'B', 'A', 'A', 'A', None, None, None, 'A', 'A', 'A', 'A', 'B', 'D']\n",
      "12\n",
      "['B', None, 'A', 'A', 'B', 'B', None, 'A', None, 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'D', 'A', 'A', 'D', 'D', 'D']\n",
      "15\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A']\n",
      "14\n",
      "['A', 'C', 'A', None, None, 'C', None, 'A', 'C', 'C', 'C', 'A', 'C', 'C', 'D']\n",
      "12\n",
      "['C', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'A', 'C', 'A', 'C', 'C', 'D', 'A']\n",
      "15\n",
      "['C', 'A', 'B', 'B', 'A', 'D', 'D', 'C', 'D', 'B', 'B', 'B', 'A', 'D', 'B']\n",
      "15\n",
      "['A', 'A', 'B', None, 'C', 'D', None, 'A', None, None, 'A', 'D', 'D', 'D', 'C']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, None, None, 'C', 'C', 'A', 'C', 'B', 'B']\n",
      "12\n",
      "['B', None, 'A', None, 'A', 'C', None, 'A', None, 'A', None, 'B', 'A', 'A', 'A']\n",
      "10\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'A', 'A', 'D', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B']\n",
      "15\n",
      "['A', 'C', 'A', 'A', 'A', 'C', 'A', 'C', None, 'C', 'C', 'B', 'C', 'B', 'C']\n",
      "14\n",
      "['D', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "15\n",
      "['A', 'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'C', 'A', 'B']\n",
      "15\n",
      "['D', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'A', 'A', 'A', 'A', 'B', 'A', 'A']\n",
      "15\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'D', 'A', 'C', 'B']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'A', 'C', 'A', 'B']\n",
      "15\n",
      "['D', 'D', 'A', 'A', 'A', 'B', 'D', 'C', 'B', 'D', 'A', 'C', 'B', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'D', 'A', 'A', 'A', None, 'A', 'A', 'D', 'A', 'D', 'D', 'D', 'B']\n",
      "14\n",
      "['A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'D', 'B', 'C']\n",
      "15\n",
      "['A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None]\n",
      "13\n",
      "['A', 'A', 'D', 'D', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['A', None, 'B', None, 'A', 'B', None, 'B', 'B', 'B', None, 'C', 'C', 'A', 'B']\n",
      "11\n",
      "['A', None, 'B', None, None, None, None, None, None, 'C', 'A', 'A', 'C', 'C', 'B']\n",
      "8\n",
      "['C', None, 'C', 'C', 'C', 'D', None, 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "13\n",
      "['A', None, 'D', None, 'C', 'B', None, 'D', 'A', 'A', 'D', 'C', 'A', 'B', 'D']\n",
      "12\n",
      "['C', 'A', 'A', 'C', 'A', 'A', 'C', 'C', 'A', 'C', 'A', 'C', 'A', 'C', 'C']\n",
      "15\n",
      "['A', None, 'D', None, 'A', 'B', None, 'A', None, 'B', 'B', 'B', 'B', 'B', 'A']\n",
      "11\n",
      "['C', 'A', 'A', 'A', 'C', 'C', 'C', 'C', 'A', 'C', 'A', 'C', 'C', 'C', 'A']\n",
      "15\n",
      "['A', None, 'C', None, None, 'A', None, 'C', 'C', 'C', None, 'C', 'A', 'C', 'C']\n",
      "10\n",
      "['B', None, 'B', None, 'B', 'B', None, 'B', 'B', 'C', 'B', 'D', 'B', 'A', 'C']\n",
      "12\n",
      "['A', 'A', 'B', None, 'B', 'A', None, 'A', 'D', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "13\n",
      "['A', None, 'C', 'A', 'A', 'C', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'B', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C']\n",
      "14\n",
      "['B', None, 'B', None, None, 'B', None, 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B']\n",
      "11\n",
      "['A', 'A', 'A', None, None, None, None, None, 'A', 'B', 'B', 'D', 'C', 'A', 'B']\n",
      "10\n",
      "['A', None, 'C', None, 'A', 'A', 'D', 'D', 'C', 'D', 'A', 'D', 'A', 'D', 'C']\n",
      "13\n",
      "['A', 'A', 'A', 'C', 'C', 'A', 'C', 'A', None, 'A', 'A', 'A', 'C', 'B', 'A']\n",
      "14\n",
      "['A', 'B', 'A', None, 'A', 'A', 'B', 'B', None, 'B', 'A', 'A', 'A', 'B', 'B']\n",
      "13\n",
      "['A', None, 'A', None, 'A', 'B', None, 'B', 'A', 'C', 'A', 'A', 'A', 'A', 'B']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'D', 'D']\n",
      "13\n",
      "['A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', None, 'A', 'D', 'A', 'A', 'A', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A']\n",
      "14\n",
      "['B', None, 'B', 'B', 'A', 'B', None, 'B', 'B', 'B', 'B', 'B', 'B', 'D', None]\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', None, 'A', 'A', 'C', 'A', None, 'C', 'C', 'A', 'A', 'A', 'C', 'C', 'B']\n",
      "13\n",
      "['A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'D', 'B', 'B', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'C', 'B', 'B']\n",
      "15\n",
      "['A', None, 'C', 'A', 'A', 'A', None, 'C', 'C', 'C', 'A', 'B', 'B', 'B', 'A']\n",
      "13\n",
      "['A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'D', 'D', 'D']\n",
      "14\n",
      "['A', 'D', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'C', 'A', 'A', 'A', 'D', 'A', 'A', 'D', 'A', 'A']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B']\n",
      "15\n",
      "['B', 'A', 'A', 'A', 'B', 'A', None, 'D', 'B', 'C', 'C', 'D', 'A', 'B', 'A']\n",
      "14\n",
      "['A', 'C', 'D', 'B', 'C', 'C', None, 'C', 'C', 'C', 'B', 'C', 'B', 'C', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C', 'A', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['C', 'C', 'C', None, 'C', 'D', None, 'D', 'D', 'D', 'C', 'C', 'D', 'C', 'A']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'D', 'D']\n",
      "15\n",
      "['C', None, 'B', None, 'B', 'C', None, None, 'B', 'B', 'C', 'B', 'B', 'B', 'B']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'D', 'B', None, 'B', 'A', 'B', 'A', 'D', 'D']\n",
      "14\n",
      "['C', None, 'B', 'A', 'C', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'C', None]\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "15\n",
      "['C', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'C', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'D', 'D', 'A', '4', 'A', 'C', 'C', 'C', 'D', 'A', 'A', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'C', 'A', 'A', 'C', 'A', 'C', 'A', 'C']\n",
      "15\n",
      "['B', 'A', 'D', 'A', 'B', 'D', 'A', 'C', 'A', 'B', 'A', 'A', 'D', 'B', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'A', 'C', 'A', 'A', 'A', 'B', 'A', 'A', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'B', 'A', 'A', None, 'D', 'A', 'A', 'B', 'B', 'B', 'A', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'C', None, 'A', 'A', 'A', 'A', 'A', 'C', 'D', 'A']\n",
      "14\n",
      "['D', None, 'C', None, 'B', 'C', None, 'A', 'A', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "12\n",
      "['A', 'A', 'C', 'A', 'A', 'A', None, 'C', 'A', 'C', 'A', 'C', 'A', 'C', 'A']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'C', 'A', 'A', 'A', None]\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'B', 'C', 'A', 'C', 'C', 'A', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['A', 'A', 'A', None, 'A', 'B', None, 'B', 'A', 'B', 'B', 'B', 'D', 'D', 'B']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'C', 'B']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'C']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "14\n",
      "['A', 'C', 'A', 'C', 'C', 'C', 'C', 'D', 'C', 'A', 'C', 'B', 'B', 'D', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', None, 'A', 'A', None, 'C', 'A', 'C', 'A', 'A', 'A', 'A', 'A']\n",
      "12\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['D', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'A', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "15\n",
      "['A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A']\n",
      "14\n",
      "['A', None, 'B', None, 'A', 'A', None, None, 'B', 'B', 'A', 'A', 'B', 'B', 'B']\n",
      "11\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B']\n",
      "15\n",
      "['A', 'A', 'D', 'A', 'D', 'A', None, 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "14\n",
      "['A', None, 'B', 'A', 'B', 'A', 'A', None, 'A', 'B', 'C', 'B', 'B', 'A', 'B']\n",
      "13\n",
      "['D', 'C', 'A', None, 'C', 'D', None, 'A', 'A', 'C', 'A', 'D', 'C', 'D', 'A']\n",
      "13\n",
      "['A', 'C', 'C', 'A', 'C', 'C', 'D', 'D', None, 'D', 'D', 'C', 'C', 'C', None]\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'C', 'D', 'C', 'D']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', None, 'A', 'A', 'C', 'D', None, 'B', 'A', 'C', 'B', 'D', 'B', 'C', 'C']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'B', 'B', 'A']\n",
      "15\n",
      "['D', 'D', 'A', 'D', 'A', 'D', None, 'A', 'A', 'D', 'A', 'A', 'A', 'C', 'C']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'A', 'C', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'B']\n",
      "15\n",
      "['A', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'A', 'D', 'B', 'D', 'B', 'D', 'A']\n",
      "15\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'B', 'B', 'D', 'B']\n",
      "15\n",
      "['A', 'B', 'B', 'A', 'A', 'C', None, 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'C']\n",
      "14\n",
      "['B', 'A', 'A', 'C', 'C', 'B', 'D', 'A', None, 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "14\n",
      "['B', 'C', 'C', 'B', 'B', 'C', 'B', 'D', 'B', 'B', 'B', 'D', 'B', 'B', 'D']\n",
      "15\n",
      "['B', None, 'A', None, 'A', 'B', 'B', 'D', 'D', 'B', 'B', 'B', 'B', 'B', 'D']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'D', 'D', 'A', 'A', 'D', 'D', 'D', 'D', 'A', 'D']\n",
      "15\n",
      "['A', 'B', 'B', 'A', 'B', 'A', 'D', 'B', 'B', 'B', 'A', 'A', 'D', 'A', 'A']\n",
      "15\n",
      "['D', 'C', None, 'D', 'D', 'D', 'D', 'D', 'C', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "14\n",
      "['D', 'D', 'D', 'D', 'D', 'D', None, 'D', 'D', 'D', 'A', 'D', 'D', 'D', 'D']\n",
      "14\n",
      "['A', 'A', 'A', 'A', 'B', 'A', 'B', None, 'B', 'D', 'C', 'A', 'C', 'B', 'B']\n",
      "14\n",
      "['C', None, None, None, 'A', 'A', None, 'D', 'A', 'D', 'A', 'D', 'A', 'B', 'B']\n",
      "11\n",
      "['A', 'A', None, 'A', 'A', 'A', 'A', None, 'A', 'A', 'A', 'A', 'C', 'D', 'A']\n",
      "13\n",
      "['D', 'B', 'D', 'B', 'B', 'D', 'D', 'D', None, 'A', 'D', 'A', 'D', 'A', 'D']\n",
      "14\n",
      "['B', None, 'B', None, 'B', 'B', None, 'C', 'B', 'B', 'D', 'D', 'D', 'B', 'B']\n",
      "12\n",
      "['A', 'A', 'A', 'B', 'A', 'A', 'B', 'A', 'D', 'A', 'D', None, 'B', 'B', 'A']\n",
      "14\n",
      "['A', 'A', 'B', 'A', 'B', 'A', 'A', None, None, 'A', 'B', 'C', 'A', 'D', 'C']\n",
      "13\n",
      "['A', 'A', 'A', 'A', 'A', 'A', None, 'A', None, 'A', 'A', 'A', 'C', 'B', 'B']\n",
      "13\n",
      "['A', 'D', 'D', 'D', 'A', 'A', 'D', 'D', 'B', 'B', 'A', 'D', 'A', 'B', 'C']\n",
      "15\n",
      "['C', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'C']\n",
      "15\n",
      "['A', None, 'A', 'A', 'C', 'A', None, None, None, None, None, 'B', 'C', None, 'B']\n",
      "8\n",
      "['A', 'A', 'D', 'A', 'A', 'A', None, 'B', 'D', 'A', 'A', 'D', 'A', 'A', 'A']\n",
      "14\n",
      "['C', 'B', 'A', 'B', 'B', 'C', None, 'B', None, 'B', 'B', 'C', 'B', 'A', 'D']\n",
      "13\n",
      "['A', 'A', 'B', 'B', 'B', 'A', 'D', 'A', 'B', 'B', 'D', 'B', 'B', 'D', 'D']\n",
      "15\n",
      "['B', 'B', 'B', 'B', 'B', 'B', None, 'B', 'B', 'B', 'A', 'B', 'C', 'B', 'A']\n",
      "14\n",
      "['A', 'D', 'A', 'D', 'D', 'D', None, 'D', None, 'D', 'A', 'A', 'A', 'D', 'D']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for item in data2:\n",
    "    # print(item['scenario_index'])\n",
    "    l = [item[i][1] for i in model_nicks]\n",
    "    print(l)\n",
    "    print(len([i for i in l if i is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "count = 0\n",
    "for item in data2:\n",
    "    answer_choices = set([item[i][1].upper() for i in model_nicks if item[i][1] is not None])\n",
    "    print(answer_choices)\n",
    "    combos = list(itertools.combinations(answer_choices, 2))\n",
    "    print(combos)\n",
    "    count += len(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6cfcf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n"
     ]
    }
   ],
   "source": [
    "for answer1, answer2 in combos:\n",
    "    print(answer1, answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4087baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = {}\n",
    "\n",
    "model_nicks = ['a','b','c','d']\n",
    "\n",
    "for i in range(4):\n",
    "    evaluation[model_nicks[i]] = []\n",
    "    for answer1, answer2 in [['a','b'], ['a','c']]:\n",
    "\n",
    "        judge_response = 'hi'\n",
    "\n",
    "        evaluation[model_nicks[i]].append([answer1, answer2, judge_response])\n",
    "\n",
    "        # print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "300172d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [['a', 'b', 'hi'], ['a', 'c', 'hi']],\n",
       " 'b': [['a', 'b', 'hi'], ['a', 'c', 'hi']],\n",
       " 'c': [['a', 'b', 'hi'], ['a', 'c', 'hi']],\n",
       " 'd': [['a', 'b', 'hi'], ['a', 'c', 'hi']]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dcf0c7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(425, 448)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 19\n",
    "r = np.linspace(0,448,21)[k:k+2]\n",
    "range(int(r[0]), int(r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e523053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c91a0851",
   "metadata": {},
   "source": [
    "## getting GPQA comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67f345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "events = [name for name in os.listdir('transcript_gpqa/') if '2025' in name]\n",
    "data = []\n",
    "for name in events:\n",
    "    with open(f\"transcript_gpqa/{name}/evaluations.json\", 'r') as file:\n",
    "        data.extend(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812ffebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(data, key=lambda x: x['scenario_index'])\n",
    "json.dump(data, open('gpqa_comparisons.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aaa679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abaaa4f",
   "metadata": {},
   "source": [
    "## forming evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f2454684",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Grok 3 Mini\": \"grok-3-mini\",\n",
    "    # \"Gemini 2.5 Flash\": \"gemini-2.5-flash\",\n",
    "    # \"GPT oss 120b\": \"gpt-oss-120b\",\n",
    "    \"Qwen3 235B A22B Instruct 2507\": \"qwen/qwen3-235b-a22b-2507\",\n",
    "    \"Kimi K2 0905\": \"moonshotai/kimi-k2-0905\",\n",
    "    \"Qwen3 Next 80B A3B Instruct\": \"qwen/qwen3-next-80b-a3b-instruct\",\n",
    "    \"Llama 4 Maverick\": \"meta-llama/llama-4-maverick\",\n",
    "    \"DeepSeek V3 0324\": \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"Gemini 2.5 Flash Lite\": \"gemini-2.5-flash-lite\",\n",
    "    \"Gemini 2.0 Flash\": \"gemini-2.0-flash-001\",\n",
    "    \"Llama 4 Scout\": \"meta-llama/llama-4-scout\",\n",
    "    \"Gemini 2.0 Flash Lite\": \"gemini-2.0-flash-lite-001\",\n",
    "    \"Llama 3.3 70b Instruct\": \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"Qwen2.5 72B Instruct\": \"qwen/qwen-2.5-72b-instruct\",\n",
    "    # \"Qwen3 235B A22B\": \"qwen/qwen3-235b-a22b\",\n",
    "    \"Llama 3.1 70B Instruct\": \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"GPT 4o mini\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"GPT 3.5 Turbo\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "model_nicks = list(models.keys())\n",
    "num_models = len(model_nicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef2107da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "responses = json.load(open('transcript_gpqa/gpqa_responses.json', 'r'))\n",
    "judgments = json.load(open('transcript_gpqa/gpqa_judgments.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1fc89b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of judge comparisons without a choice: 17875\n"
     ]
    }
   ],
   "source": [
    "comparisons = []\n",
    "\n",
    "no_choice_count = 0\n",
    "for scenario in range(448):\n",
    "    responses_dict = [i for i in responses if i['scenario_index'] == scenario][0]\n",
    "    judgments_dict = [i for i in judgments if i['scenario_index'] == scenario][0]\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_models):\n",
    "            for k in range(j+1, num_models):\n",
    "                if j == k: continue\n",
    "\n",
    "                answer_j = responses_dict[model_nicks[j]][1]\n",
    "                answer_k = responses_dict[model_nicks[k]][1]\n",
    "\n",
    "                if answer_j is None or answer_k is None: continue\n",
    "                if answer_j == answer_k: \n",
    "                    comparisons.append([0, scenario, i, j, k, 0])\n",
    "                    continue\n",
    "\n",
    "                judgment_i = [None, None, None]\n",
    "                for judgment in judgments_dict[model_nicks[i]]:\n",
    "                    if set(judgment[:2]) == set([answer_j, answer_k]) and judgment[2] is not None:\n",
    "                        judgment_i = judgment\n",
    "                        break\n",
    "                if judgment_i[2] is None: continue\n",
    "                \n",
    "                try:\n",
    "                    m = int(re.search(r'<choice>(.)</choice>', judgment_i[2]).group(1))\n",
    "                    if m in [1,2]:\n",
    "                        # if the judge saw answers in the same order as j,k\n",
    "                        if answer_j == judgment_i[0]:\n",
    "                            # comparisons.append([scenario, i, j, k, 2-m]) # map {1,2} to {1,0}, i.e. if it chose answer 1, record win for j\n",
    "                            comparisons.append([0, scenario, i, j, k, m]) # report {1,2}, i.e. if it chose answer 1, record win for j\n",
    "                        # if the judge saw answers in the opposite order as j,k\n",
    "                        else:\n",
    "                            # comparisons.append([scenario, i, j, k, m-1]) # map {1,2} to {0,1}, i.e. if it chose answer 1, record win for k\n",
    "                            comparisons.append([0, scenario, i, j, k, 3-m]) # map {1,2} to {2,1}, i.e. if it chose answer 1, record win for k\n",
    "                except:\n",
    "                    no_choice_count += 1\n",
    "                    pass\n",
    "\n",
    "print(f'Number of judge comparisons without a choice: {no_choice_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b04425a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572708"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf641c",
   "metadata": {},
   "source": [
    "## Training BT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0f61ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BT import *\n",
    "from eigentrust import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2573a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vector_bt(model, dataloader, lr, weight_decay, max_epochs, device, save_path=None, normalize=False, use_btd=False):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    if use_btd:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for i, j, k, r in dataloader:\n",
    "            i = i.to(device)\n",
    "            j = j.to(device)\n",
    "            k = k.to(device)\n",
    "            r = r.to(device)\n",
    "\n",
    "            if use_btd:\n",
    "                r = r.long()  # CrossEntropyLoss expects long tensor\n",
    "                logits = model(i, j, k)\n",
    "                loss = loss_fn(logits, r) # CE expects logits, unnormalized, as it has built in softmax\n",
    "            else:\n",
    "                p = model(i, j, k)\n",
    "                loss = loss_fn(p, r)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if normalize:\n",
    "                with torch.no_grad():\n",
    "                    model.v.weight.data = F.normalize(model.v.weight.data, p=2, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * r.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        loss_history.append(avg_loss)\n",
    "    \n",
    "        if len(loss_history) >= 3 and  np.average(np.abs(np.diff(loss_history[-3:]))) <= .0001:\n",
    "            print('loss converged, breaking')\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch:>3d}, Loss = {avg_loss:.4f}\")\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9bfd0682",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset \u001b[38;5;241m=\u001b[39m Comparisons(comparisons), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m VectorBT(num_models, d)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_vector_bt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNORMALIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_btd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_BTD\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[161], line 16\u001b[0m, in \u001b[0;36mtrain_vector_bt\u001b[0;34m(model, dataloader, lr, weight_decay, max_epochs, device, save_path, normalize, use_btd)\u001b[0m\n\u001b[1;32m     13\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j, k, r \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     17\u001b[0m     i \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     j \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-metal/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/GitHub/EigenBench/BT.py:35\u001b[0m, in \u001b[0;36mComparisons.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 35\u001b[0m     l, i, j, k, r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(i, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), \\\n\u001b[1;32m     37\u001b[0m            torch\u001b[38;5;241m.\u001b[39mtensor(j, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), \\\n\u001b[1;32m     38\u001b[0m            torch\u001b[38;5;241m.\u001b[39mtensor(k, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), \\\n\u001b[1;32m     39\u001b[0m            torch\u001b[38;5;241m.\u001b[39mtensor(r, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "num_models = len(set([i[1] for i in comparisons]))\n",
    "\n",
    "d = 2\n",
    "NORMALIZE = False\n",
    "USE_BTD = False\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 0\n",
    "max_epochs = 1000\n",
    "\n",
    "batch_size=32\n",
    "dataloader = DataLoader(dataset = Comparisons(comparisons), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = VectorBT(num_models, d)\n",
    "train_vector_bt(\n",
    "    model,\n",
    "    dataloader,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    max_epochs=max_epochs,\n",
    "    device='cpu',\n",
    "    save_path=None,\n",
    "    normalize=NORMALIZE,\n",
    "    use_btd=USE_BTD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ac04a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:00<00:00, 1860.93it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "T = compute_trust_matrix(model, device)\n",
    "T = row_normalize(T)\n",
    "t = eigentrust(T, alpha=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc34b3",
   "metadata": {},
   "source": [
    "## TRaining BTD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "109781dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BT_criteria import *\n",
    "from eigentrust import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ab9f8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vector_bt(model, dataloader, lr, weight_decay, max_epochs, device, save_path=None, normalize=False, use_btd=False):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    if use_btd:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for c_idx, i_idx, j_idx, k_idx, r in dataloader:\n",
    "            c_idx = c_idx.to(device)\n",
    "            i_idx = i_idx.to(device)\n",
    "            j_idx = j_idx.to(device)\n",
    "            k_idx = k_idx.to(device)\n",
    "            r = r.to(device)\n",
    "\n",
    "            if use_btd:\n",
    "                r = r.long()  # CrossEntropyLoss expects long tensor\n",
    "\n",
    "                logits = model(c_idx, i_idx, j_idx, k_idx)\n",
    "                loss = loss_fn(logits, r) # CE expects logits, unnormalized, as it has built in softmax\n",
    "            else:\n",
    "                p = model(i_idx, j_idx, k_idx)\n",
    "                loss = loss_fn(p, r)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if normalize:\n",
    "                with torch.no_grad():\n",
    "                    model.v.weight.data = F.normalize(model.v.weight.data, p=2, dim=1)\n",
    "\n",
    "            total_loss += loss.item() * r.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch:>3d}, Loss = {avg_loss:.4f}\")\n",
    "    \n",
    "        if len(loss_history) >= 3 and  np.average(np.abs(np.diff(loss_history[-3:]))) <= .0001:\n",
    "            print('loss converged, breaking')\n",
    "            break\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b8b7e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1, Loss = 0.9634\n",
      "Epoch   2, Loss = 0.9548\n",
      "Epoch   3, Loss = 0.9546\n",
      "Epoch   4, Loss = 0.9546\n",
      "Epoch   5, Loss = 0.9547\n",
      "loss converged, breaking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:00<00:00, 1151.39it/s]\n"
     ]
    }
   ],
   "source": [
    "num_models = 15\n",
    "num_criteria = 1\n",
    "\n",
    "d = 2\n",
    "NORMALIZE=False\n",
    "USE_BTD=True\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 0\n",
    "max_epochs = 1000\n",
    "\n",
    "batch_size=32\n",
    "dataloader = DataLoader(dataset = Comparisons(comparisons), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = VectorBTD(num_criteria, num_models, d)\n",
    "train_vector_bt(\n",
    "    model,\n",
    "    dataloader,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    max_epochs=max_epochs,\n",
    "    device='cpu',\n",
    "    save_path=None,\n",
    "    normalize=NORMALIZE,\n",
    "    use_btd=USE_BTD\n",
    ")\n",
    "\n",
    "device = 'cpu'\n",
    "T = compute_trust_matrix_ties(model, device)\n",
    "t = eigentrust(T, alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "26e334b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0737, 0.0756, 0.0681, 0.0758, 0.0735, 0.0706, 0.0679, 0.0717, 0.0686,\n",
       "        0.0651, 0.0660, 0.0627, 0.0595, 0.0531, 0.0481])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9862f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 0, 4, 7, 5, 8, 2, 6, 10, 9, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(np.argsort(t.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bfc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "918a327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau distance: 12\n",
      "Kendall tau distance: 12\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def kendall_tau_distance(rank1, rank2):\n",
    "    \"\"\"\n",
    "    Compute the Kendall tau distance between two rankings.\n",
    "    \n",
    "    rank1, rank2: lists of items representing two permutations of the same set.\n",
    "    Returns: integer distance (number of discordant pairs).\n",
    "    \"\"\"\n",
    "    if set(rank1) != set(rank2):\n",
    "        raise ValueError(\"Rankings must contain the same elements\")\n",
    "\n",
    "    # Map each item in rank2 to its position\n",
    "    pos2 = {item: i for i, item in enumerate(rank2)}\n",
    "\n",
    "    # Count discordant pairs\n",
    "    discordant = 0\n",
    "    for i, j in combinations(range(len(rank1)), 2):\n",
    "        a, b = rank1[i], rank1[j]\n",
    "        # Compare orderings in rank1 and rank2\n",
    "        if (pos2[a] - pos2[b]) * (i - j) < 0:\n",
    "            discordant += 1\n",
    "\n",
    "    return discordant\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "rank1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]       # ground truth\n",
    "rank2 = [1, 3, 0, 4, 7, 5, 8, 6, 2, 10, 9, 11, 12, 13, 14]      # model ranking\n",
    "rank3 = [i-1 for i in [3, 2, 8, 1, 4, 6, 9, 5, 7, 11, 10, 12, 13, 14, 15]]\n",
    "print(\"Kendall tau distance:\", kendall_tau_distance(rank1, rank2))\n",
    "print(\"Kendall tau distance:\", kendall_tau_distance(rank1, rank3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feac5c1",
   "metadata": {},
   "source": [
    "Kendall tau distance was 12 for both BT and BTD models! (ties don't matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e0203141",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0.0737, 0.0756, 0.0681, 0.0758, 0.0735, 0.0706, 0.0679, 0.0717, 0.0686, 0.0651, 0.0660, 0.0627, 0.0595, 0.0531, 0.0481]\n",
    "gpqa = [.84, .775, .758, .729, .698, .684, .646, .621, .572, .515, .505, .49, .417, .402, .308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5dac7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 0, 4, 7, 5, 8, 2, 6, 10, 9, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(reversed(np.argsort(np.array(t))))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "20fc63ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0737 3\n",
      "0.0756 2\n",
      "0.0681 8\n",
      "0.0758 1\n",
      "0.0735 4\n",
      "0.0706 6\n",
      "0.0679 9\n",
      "0.0717 5\n",
      "0.0686 7\n",
      "0.0651 11\n",
      "0.066 10\n",
      "0.0627 12\n",
      "0.0595 13\n",
      "0.0531 14\n",
      "0.0481 15\n"
     ]
    }
   ],
   "source": [
    "ranking = []\n",
    "for i, val in enumerate(t):\n",
    "    print(val, l.index(i)+1)\n",
    "    ranking.append(l.index(i)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "569cf16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t, gpqa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d7d18c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\texttt{Grok 3 Mini}\n",
      "\\texttt{Qwen3 235B A22B Instruct 2507}\n",
      "\\texttt{Kimi K2 0905}\n",
      "\\texttt{Qwen3 Next 80B A3B Instruct}\n",
      "\\texttt{Llama 4 Maverick}\n",
      "\\texttt{DeepSeek V3 0324}\n",
      "\\texttt{Gemini 2.5 Flash Lite}\n",
      "\\texttt{Gemini 2.0 Flash}\n",
      "\\texttt{Llama 4 Scout}\n",
      "\\texttt{Gemini 2.0 Flash Lite}\n",
      "\\texttt{Llama 3.3 70b Instruct}\n",
      "\\texttt{Qwen2.5 72B Instruct}\n",
      "\\texttt{Llama 3.1 70B Instruct}\n",
      "\\texttt{GPT 4o mini}\n",
      "\\texttt{GPT 3.5 Turbo}\n"
     ]
    }
   ],
   "source": [
    "for i in model_nicks:\n",
    "    print(f'\\\\texttt{{{i}}}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
